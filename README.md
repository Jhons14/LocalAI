# ğŸ§  LLM Chat Interface

Una aplicaciÃ³n de cÃ³digo abierto para interactuar fÃ¡cilmente con modelos de lenguaje (LLM), ya sea en local usando [Ollama](https://ollama.com/) o en la nube a travÃ©s de OpenAI (ChatGPT) con una API key.

## ğŸš€ CaracterÃ­sticas

- âœ… Compatible con modelos LLM locales (Ollama)  
- â˜ï¸ Soporte para ChatGPT vÃ­a API Key (OpenAI)  
- ğŸ§© Frontend moderno con React + Vite  
- ğŸ Backend robusto en Python (FastAPI)  
- ğŸ” GestiÃ³n segura de claves API  
- ğŸ’¬ Interfaz tipo chat con historial  
- ğŸ¨ UI responsiva y amigable  

## ğŸ§± TecnologÃ­as

| Parte      | TecnologÃ­a                |
|------------|---------------------------|
| Frontend   | React, Vite, Tailwind CSS |
| Backend    | Python, FastAPI           |
| LLM Local  | Ollama                    |
| LLM Nube   | OpenAI (ChatGPT)          |

## ğŸ› ï¸ InstalaciÃ³n

### 1. Clona el repositorio

```bash
git clone https://github.com/Jhons14/LocalAI.git
cd LocalAI
```

### 2. Configura el backend (Python)

```bash
cd backend
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

Crea un archivo `.env` con tus variables necesarias:


Inicia el backend:

```bash
fastapi run --reload
```

### 3. Configura el frontend (React + Vite)

```bash
cd ../frontend
npm install
npm run dev
```

## âš™ï¸ ConfiguraciÃ³n

- Puedes alternar entre LLM local y remoto mediante una configuraciÃ³n en el backend.
- El frontend se comunica con el backend mediante endpoints REST para enviar preguntas y recibir respuestas por chunks.

## ğŸ“¦ Despliegue con Docker

Puedes usar [Docker](https://www.docker.com/) o [Docker Compose](https://docs.docker.com/compose/) para ejecutar toda la app fÃ¡cilmente:

```bash
docker-compose up --build
```

AsegÃºrate de tener tus variables de entorno configuradas en los archivos `.env` correspondientes antes de levantar los contenedores.

## ğŸ”’ Seguridad

- La API key de OpenAI **no se expone** en el frontend.
- Agrega restricciones CORS apropiadas para producciÃ³n.
- Considera usar HTTPS en despliegues reales.

## ğŸ§ª TODO

- [ ] AutenticaciÃ³n de usuario  
- [ ] Guardar historial en base de datos  
- [ ] Soporte para mÃºltiples modelos en tiempo real  
- [ ] Soporte para carga de archivos y anÃ¡lisis de documentos  

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

## âœ¨ Autor

Desarrollado por [Jhon Steven Orjuela](https://www.jstevenon.com/) â€” Â¡Contribuciones y estrellas son bienvenidas!
